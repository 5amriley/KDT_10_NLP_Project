{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.functional import accuracy, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "horrorDF = pd.read_excel(\n",
    "    \"../DATA/2조 괴담 파일.xlsx\", skiprows=0, header=1, sheet_name=\"SY\", usecols=[3]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오늘 학교에서 모의고사보는데 가위눌리다가 한쪽눈만 떠진상태로 교실에서 내 다리에 올...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그녀는 날 사랑한다... 안 사랑한다... 날 사랑한다... 안 사랑한다...날 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>어린애같지만, 난 항상 지하실에서 나갈때 내 뒤를 쳐다보면서 계단을 뛰어 올라가. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>생리혈에 덩어리 같은게 있을수 있다는건 나도 알아. 근데 그게 보통 움직이는거야?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>난 별 생각없이 \"우리 모두 다함께 손뼉쳐!\" 라고 외쳤어. 다락방에서 박수 소리를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>희망봉근해에 출몰하는 네덜란드 동인도회사의 유령선을 플라잉더치맨이라고 부른다. 알류...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>T 씨가 잠에서 깨자, 1년이 경과해있었다.하지만 기억상실은 아니다.가족도, 친구도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>아르메니아 쿠니크호수에는 딱 스와코 *오미와타리 같은 자연현상이 일어난다. 호반 교...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>적도상 3만 6000킬로에 해당하는 우주 공간에,  길이 50M의 거대 물체가 떠있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1865년 미국. 어느 날, 1명의 남자가 며칠 연속으로 신기한 꿈을 꾸었다. 그 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TEXT\n",
       "0    오늘 학교에서 모의고사보는데 가위눌리다가 한쪽눈만 떠진상태로 교실에서 내 다리에 올...\n",
       "1    그녀는 날 사랑한다... 안 사랑한다... 날 사랑한다... 안 사랑한다...날 사...\n",
       "2    어린애같지만, 난 항상 지하실에서 나갈때 내 뒤를 쳐다보면서 계단을 뛰어 올라가. ...\n",
       "3      생리혈에 덩어리 같은게 있을수 있다는건 나도 알아. 근데 그게 보통 움직이는거야?\\n\n",
       "4    난 별 생각없이 \"우리 모두 다함께 손뼉쳐!\" 라고 외쳤어. 다락방에서 박수 소리를...\n",
       "..                                                 ...\n",
       "994  희망봉근해에 출몰하는 네덜란드 동인도회사의 유령선을 플라잉더치맨이라고 부른다. 알류...\n",
       "995  T 씨가 잠에서 깨자, 1년이 경과해있었다.하지만 기억상실은 아니다.가족도, 친구도...\n",
       "996  아르메니아 쿠니크호수에는 딱 스와코 *오미와타리 같은 자연현상이 일어난다. 호반 교...\n",
       "997  적도상 3만 6000킬로에 해당하는 우주 공간에,  길이 50M의 거대 물체가 떠있...\n",
       "998  1865년 미국. 어느 날, 1명의 남자가 며칠 연속으로 신기한 꿈을 꾸었다. 그 ...\n",
       "\n",
       "[999 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horrorDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Series name: TEXT\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "999 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "horrorSR = horrorDF[\"TEXT\"].str.replace(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z\\d ]\", \"\", regex=True)\n",
    "horrorSR.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘 학교에서 모의고사보는데 가위눌리다가 한쪽눈만 떠진상태로 교실에서 내 다리에 올라와있는 귀신봤어',\n",
       " '그녀는 날 사랑한다 안 사랑한다 날 사랑한다 안 사랑한다날 사 어 더 이상 떼어낼 팔다리가 없네 넌 처음부터 날 사랑하지 않았구나',\n",
       " '어린애같지만 난 항상 지하실에서 나갈때 내 뒤를 쳐다보면서 계단을 뛰어 올라가 난 잘못된 방향을 바라보고 있었었어',\n",
       " '생리혈에 덩어리 같은게 있을수 있다는건 나도 알아 근데 그게 보통 움직이는거야',\n",
       " '난 별 생각없이 우리 모두 다함께 손뼉쳐 라고 외쳤어 다락방에서 박수 소리를 들리기 전까진 난 내가 집에 혼자있는줄 알았어',\n",
       " '난 숲속에서 일회용 카메라를 발견했다 필름을 현상했을때 그곳엔 내가 처음으로 카메라를 발견했을때의 모습이 찍힌 사진 딱 한장만이 찍혀있었다',\n",
       " '우리 할머니는 심한 치매에 걸리셨다 매일 저녁 난 할머니가 2년전에 이미 돌아가셨다고 설명하지만 허사다',\n",
       " '버스 문이 닫히고 버스 기사의 웃음소리가 그의 뒤에서 울려퍼졌을때 지미는 자신의 실수를 알아챘다 왜 스쿨 버스가 한밤중에 달리고 있는거지',\n",
       " '저녁시간 아빠는 나에게 하루가 어땠는지 물었다 아빠의 얼굴이 약간 정중앙에서 벗어나있는것처럼 보인다는 사실을 깨달았을때 난 아빠의 어깨 너머로 도망가라고 입모양으로 말하고 있는 두려움에 빠진 엄마를 볼수 있었다',\n",
       " '아빠 나 무서운 꿈 꿨어 오 공주님 난 아빠가 아냐']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = horrorSR.to_list()\n",
    "sentences[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(\"\".join(sentences)))\n",
    "char_to_id = {char: idx for idx, char in enumerate(char_set)}\n",
    "id_to_char = {idx: char for idx, char in enumerate(char_set)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = [], []\n",
    "sequence_length = 10\n",
    "\n",
    "for sentence in sentences:\n",
    "    for i in range(0, len(sentence) - sequence_length):\n",
    "        x_str = sentence[i : i + sequence_length]\n",
    "        y_str = sentence[i + 1 : i + sequence_length + 1]\n",
    "        # print(i, x_str, '->', y_str)\n",
    "        X_data.append([char_to_id[c] for c in x_str])\n",
    "        y_data.append([char_to_id[c] for c in y_str])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([676, 1054, 455, 218, 433, 778, 357, 455, 340, 1100],\n",
       " [1054, 455, 218, 433, 778, 357, 455, 340, 1100, 1014])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0], y_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 size: 116572, shape: (116572, 10), dim: 2\n",
      "출력 데이터 size: 116572, shape: (116572, 10), dim: 2\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"입력 데이터 size: {len(X_data)}, shape: {np.array(X_data).shape}, dim: {np.array(X_data).ndim}\"\n",
    ")\n",
    "print(\n",
    "    f\"출력 데이터 size: {len(y_data)}, shape: {np.array(y_data).shape}, dim: {np.array(y_data).ndim}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_data,\n",
    "        y_data,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.in_text = torch.FloatTensor(X_data)\n",
    "        self.out_text = torch.FloatTensor(y_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.out_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.in_text[index], self.out_text[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharGRU(nn.Module):\n",
    "    def __init__(\n",
    "        self, dict_size, embedding_dim, hidden_size, sequence_length, n_layers, dropout\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # self.embedding = nn.Embedding(dict_size, embedding_dim)\n",
    "        self.gru = nn.GRU(\n",
    "            dict_size, hidden_size, n_layers, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size, dict_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        # self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        # embedded = self.embedding(text)\n",
    "        output, _ = self.gru(text)\n",
    "        # last_output = output[:, -1, :]\n",
    "        last_output = self.dropout(output)\n",
    "        return self.linear(last_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1822\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dict_size = len(char_to_id)\n",
    "\n",
    "hidden_size = 64\n",
    "\n",
    "embedding_dim = 128\n",
    "\n",
    "n_layer = 10\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "learningDS = CharDataset(X_data, y_data)\n",
    "learningDL = DataLoader(dataset=learningDS, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "classifier = CharGRU(\n",
    "    dict_size, embedding_dim, hidden_size, sequence_length, n_layer, 0.5\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = optim.AdamW(classifier.parameters(), 0.001)\n",
    "\n",
    "schduler = optim.lr_scheduler.StepLR(optimizer, 5, 0.1)\n",
    "\n",
    "\n",
    "print(len(learningDL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CharGRU                                  --\n",
       "├─GRU: 1-1                               478,080\n",
       "├─Linear: 1-2                            81,510\n",
       "├─Dropout: 1-3                           --\n",
       "=================================================================\n",
       "Total params: 559,590\n",
       "Trainable params: 559,590\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def learning(\n",
    "    epoch, epochs, model, dataLoader, criterion, optimizer, device, mode=\"train\"\n",
    "):\n",
    "    if mode == \"train\":\n",
    "        model.train()\n",
    "        is_train = True\n",
    "    elif mode == \"test\":\n",
    "        model.eval()\n",
    "        is_train = False\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Must be 'train' or 'test'\")\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        pbar = tqdm(enumerate(dataLoader), total=len(dataLoader))\n",
    "        for step, (in_text, out_text) in pbar:\n",
    "            in_text, out_text = in_text.to(device), out_text.to(device)\n",
    "            oh_in_text = F.one_hot(in_text.long(), dict_size).float()\n",
    "            oh_out_text = F.one_hot(out_text.long(), dict_size).float()\n",
    "            pre_text = model(oh_in_text)\n",
    "            loss = criterion(pre_text, oh_out_text)\n",
    "            running_loss += loss.item()\n",
    "            acc_list.append(\n",
    "                accuracy(\n",
    "                    pre_text.argmax(2),\n",
    "                    out_text,\n",
    "                    task=\"multiclass\",\n",
    "                    num_classes=dict_size,\n",
    "                )\n",
    "            )\n",
    "            f1_list.append(\n",
    "                f1_score(\n",
    "                    pre_text.argmax(2),\n",
    "                    out_text,\n",
    "                    task=\"multiclass\",\n",
    "                    num_classes=dict_size,\n",
    "                    average=\"macro\",\n",
    "                )\n",
    "            )\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "                optimizer.step()\n",
    "                if step % 10 == 9:\n",
    "                    pbar.set_description(\n",
    "                        f\"Epoch [{epoch + 1}/{epochs}], 횟수 [{step + 1}/{len(dataLoader)}], Loss: {running_loss / 10:.4f}\"\n",
    "                    )\n",
    "                    loss_list.append(running_loss)\n",
    "                    running_loss = 0.0\n",
    "    return np.mean(loss_list), np.mean(acc_list), np.mean(f1_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, word):\n",
    "    for char in word:\n",
    "        if char in char_to_id.keys():\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred_text = (\n",
    "                    F.one_hot(torch.tensor(char_to_id[char]), dict_size)\n",
    "                    .unsqueeze(0)\n",
    "                    .float()\n",
    "                    .to(device)\n",
    "                )\n",
    "                pred_num = model(pred_text).argmax(1).item()\n",
    "                result = id_to_char[pred_num]\n",
    "        else:\n",
    "            result = \" \"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], 횟수 [1820/1822], Loss: 0.0142: 100%|██████████| 1822/1822 [02:32<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 학습 종료 ===> 손실: 0.1665, 정확도: 0.0462, f1 점수: 0.0021\n",
      "난 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 \n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "scoreList = [[], []]\n",
    "for epoch in range(epochs):\n",
    "    loss, acc, f1 = learning(\n",
    "        epoch,\n",
    "        epochs,\n",
    "        classifier,\n",
    "        learningDL,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        mode=\"train\",\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1} 학습 종료 ===> 손실: {loss:.4f}, 정확도: {acc:.4f}, f1 점수: {f1:.4f}\"\n",
    "    )\n",
    "    start = \"난\"\n",
    "    make_sentence = \"\"\n",
    "    for _ in range(100):\n",
    "        make_sentence += start\n",
    "        next_char = predict(classifier, start)\n",
    "        start = next_char\n",
    "    print(make_sentence)\n",
    "    scoreList[0].append(loss), scoreList[1].append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(classifier, \"난\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 \n"
     ]
    }
   ],
   "source": [
    "start = \"나\"\n",
    "make_sentence = \"\"\n",
    "for _ in range(100):\n",
    "    make_sentence += start\n",
    "    next_char = predict(classifier, start)\n",
    "    start = next_char\n",
    "print(make_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
